{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download the data\n",
    "cancer_data=pd.read_csv('breast-cancer-wisconsin.data.txt', header=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancer_data.columns=['Sample ID', 'Clump thickness', 'Cell size uniformity', 'Cell shape uniformity', 'Marginal adhesion', \\\n",
    "                    'Single epithelial cell size', 'Bare nuclei', 'Bland Chromatin', 'Normal nucleoli', \\\n",
    "                    'Mitoses', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jananikalyanam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/jananikalyanam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Redo classification vector with 0 and 1 instead of 2 and 4\n",
    "for i in range(0, len(cancer_data)):\n",
    "    if cancer_data['Class'][i]==2:\n",
    "        cancer_data['Class'][i]=0\n",
    "    elif cancer_data['Class'][i]==4:\n",
    "        cancer_data['Class'][i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02857142857142857, 0.05, 0.04285714285714286, 0.05714285714285714, 0.04316546762589928]\n",
      "0.0443473792395\n",
      "Logistic Classification Feature Weights\n",
      "0.279714330725 Clump thickness\n",
      "0.178373999217 Cell size uniformity\n",
      "0.510924994748 Cell shape uniformity\n",
      "0.199833313923 Marginal adhesion\n",
      "-0.00905174757519 Single epithelial cell size\n",
      "0.250860227644 Bland Chromatin\n",
      "0.120950338836 Normal nucleoli\n",
      "0.19578826994 Mitoses\n"
     ]
    }
   ],
   "source": [
    "#start with simple logistic regression. Note that I am splitting the data into five cross-validation groups \n",
    "#and averaging the error.\n",
    "\n",
    "model=LogisticRegression()\n",
    "#model=RandomForestClassifier(n_estimators=45, oob_score=True)\n",
    "#model=GradientBoostingClassifier(learning_rate=.05)\n",
    "\n",
    "#col_names=['Clump thickness', 'Cell size uniformity', 'Cell shape uniformity', 'Marginal adhesion', \\\n",
    "#                    'Single epithelial cell size', 'Bare nuclei', 'Bland Chromatin', 'Normal nucleoli', \\\n",
    "#                    'Mitoses']\n",
    "\n",
    "col_names=['Clump thickness', 'Cell size uniformity', 'Cell shape uniformity', 'Marginal adhesion', \\\n",
    "          'Single epithelial cell size', 'Bland Chromatin', 'Normal nucleoli', \\\n",
    "                    'Mitoses']\n",
    "\n",
    "mean_error=[]\n",
    "total_error=[]\n",
    "mean_values=[]\n",
    "\n",
    "temp=list(range(5))\n",
    "for i in list(range(5)):\n",
    "    temp=list(range(5))\n",
    "    temp.remove(i)\n",
    "    test=cancer_data[i::5]\n",
    "    training_setup=[cancer_data[temp[0]::5], cancer_data[temp[1]::5], cancer_data[temp[2]::5], cancer_data[temp[3]::5]]\n",
    "    training=pd.concat(training_setup)\n",
    "\n",
    "    fit=model.fit(training[col_names], training['Class'])\n",
    "    lr_prediction=fit.predict(test[col_names])\n",
    "    \n",
    "    mean_error.append(np.mean(np.abs(lr_prediction-test['Class'])))\n",
    "    \n",
    "    total_error.append(np.abs(lr_prediction-test['Class']))\n",
    "    \n",
    "    mean_values.append(np.mean(np.abs(test['Class'])))\n",
    "    \n",
    "print(mean_error)\n",
    "print(np.mean(mean_error))\n",
    "print('Logistic Classification Feature Weights')\n",
    "for i in range(0, len(test[col_names].keys())): print(fit.coef_[0][i], test[col_names].keys()[i])\n",
    "#for i in range(0, len(test[col_names].keys())): print(fit.feature_importances_[i], test[col_names].keys()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02857142857142857, 0.05, 0.03571428571428571, 0.02857142857142857, 0.050359712230215826]\n",
      "0.0386433710175\n",
      "Logistic Classification Feature Weights\n",
      "0.0639613999168 Clump thickness\n",
      "0.287631998378 Cell size uniformity\n",
      "0.246887326868 Cell shape uniformity\n",
      "0.0717794555437 Marginal adhesion\n",
      "0.110607921376 Single epithelial cell size\n",
      "0.124735043815 Bland Chromatin\n",
      "0.0820349404321 Normal nucleoli\n",
      "0.0123619136699 Mitoses\n"
     ]
    }
   ],
   "source": [
    "#Not bad, let's try the random forest next\n",
    "\n",
    "#model=LogisticRegression()\n",
    "model=RandomForestClassifier(n_estimators=45, oob_score=True)\n",
    "#model=GradientBoostingClassifier(learning_rate=.05)\n",
    "\n",
    "#col_names=['Clump thickness', 'Cell size uniformity', 'Cell shape uniformity', 'Marginal adhesion', \\\n",
    "#                    'Single epithelial cell size', 'Bare nuclei', 'Bland Chromatin', 'Normal nucleoli', \\\n",
    "#                    'Mitoses']\n",
    "\n",
    "col_names=['Clump thickness', 'Cell size uniformity', 'Cell shape uniformity', 'Marginal adhesion', \\\n",
    "          'Single epithelial cell size', 'Bland Chromatin', 'Normal nucleoli', \\\n",
    "                    'Mitoses']\n",
    "\n",
    "mean_error=[]\n",
    "total_error=[]\n",
    "mean_values=[]\n",
    "\n",
    "temp=list(range(5))\n",
    "for i in list(range(5)):\n",
    "    temp=list(range(5))\n",
    "    temp.remove(i)\n",
    "    test=cancer_data[i::5]\n",
    "    training_setup=[cancer_data[temp[0]::5], cancer_data[temp[1]::5], cancer_data[temp[2]::5], cancer_data[temp[3]::5]]\n",
    "    training=pd.concat(training_setup)\n",
    "\n",
    "    fit=model.fit(training[col_names], training['Class'])\n",
    "    lr_prediction=fit.predict(test[col_names])\n",
    "    \n",
    "    mean_error.append(np.mean(np.abs(lr_prediction-test['Class'])))\n",
    "    \n",
    "    total_error.append(np.abs(lr_prediction-test['Class']))\n",
    "    \n",
    "    mean_values.append(np.mean(np.abs(test['Class'])))\n",
    "    \n",
    "print(mean_error)\n",
    "print(np.mean(mean_error))\n",
    "print('Logistic Classification Feature Weights')\n",
    "#for i in range(0, len(test[col_names].keys())): print(fit.coef_[0][i], test[col_names].keys()[i])\n",
    "for i in range(0, len(test[col_names].keys())): print(fit.feature_importances_[i], test[col_names].keys()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02857142857142857, 0.07142857142857142, 0.04285714285714286, 0.05, 0.04316546762589928]\n",
      "0.0472045220966\n",
      "Logistic Classification Feature Weights\n",
      "0.131764392583 Clump thickness\n",
      "0.129226459986 Cell size uniformity\n",
      "0.259330735007 Cell shape uniformity\n",
      "0.0965542924177 Marginal adhesion\n",
      "0.0846792553672 Single epithelial cell size\n",
      "0.123385961806 Bland Chromatin\n",
      "0.139314117116 Normal nucleoli\n",
      "0.0357447857176 Mitoses\n"
     ]
    }
   ],
   "source": [
    "#Better, 3.9% error. Finally, let's try a gradient boosted tree\n",
    "\n",
    "#model=LogisticRegression()\n",
    "#model=RandomForestClassifier(n_estimators=45, oob_score=True)\n",
    "model=GradientBoostingClassifier(learning_rate=.05)\n",
    "\n",
    "#col_names=['Clump thickness', 'Cell size uniformity', 'Cell shape uniformity', 'Marginal adhesion', \\\n",
    "#                    'Single epithelial cell size', 'Bare nuclei', 'Bland Chromatin', 'Normal nucleoli', \\\n",
    "#                    'Mitoses']\n",
    "\n",
    "col_names=['Clump thickness', 'Cell size uniformity', 'Cell shape uniformity', 'Marginal adhesion', \\\n",
    "          'Single epithelial cell size', 'Bland Chromatin', 'Normal nucleoli', \\\n",
    "                    'Mitoses']\n",
    "\n",
    "mean_error=[]\n",
    "total_error=[]\n",
    "mean_values=[]\n",
    "\n",
    "temp=list(range(5))\n",
    "for i in list(range(5)):\n",
    "    temp=list(range(5))\n",
    "    temp.remove(i)\n",
    "    test=cancer_data[i::5]\n",
    "    training_setup=[cancer_data[temp[0]::5], cancer_data[temp[1]::5], cancer_data[temp[2]::5], cancer_data[temp[3]::5]]\n",
    "    training=pd.concat(training_setup)\n",
    "\n",
    "    fit=model.fit(training[col_names], training['Class'])\n",
    "    lr_prediction=fit.predict(test[col_names])\n",
    "    \n",
    "    mean_error.append(np.mean(np.abs(lr_prediction-test['Class'])))\n",
    "    \n",
    "    total_error.append(np.abs(lr_prediction-test['Class']))\n",
    "    \n",
    "    mean_values.append(np.mean(np.abs(test['Class'])))\n",
    "    \n",
    "print(mean_error)\n",
    "print(np.mean(mean_error))\n",
    "print('Logistic Classification Feature Weights')\n",
    "#for i in range(0, len(test[col_names].keys())): print(fit.coef_[0][i], test[col_names].keys()[i])\n",
    "for i in range(0, len(test[col_names].keys())): print(fit.feature_importances_[i], test[col_names].keys()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06480240224794086, 0.07648694846513016, 0.07235116901574656, 0.0665586396303427, 0.07444433201097703]\n",
      "0.070928698274\n"
     ]
    }
   ],
   "source": [
    "#Not quite as good, so the random forest is best so far. Let's see what a neural net can do.\n",
    "\n",
    "mean_error=[]\n",
    "total_error=[]\n",
    "mean_values=[]\n",
    "\n",
    "col_names=['Clump thickness', 'Cell size uniformity', 'Cell shape uniformity', 'Marginal adhesion', \\\n",
    "          'Single epithelial cell size', 'Bland Chromatin', 'Normal nucleoli', \\\n",
    "                    'Mitoses']\n",
    "\n",
    "batches=30\n",
    "\n",
    "temp=list(range(5))\n",
    "for i in list(range(5)):\n",
    "    temp=list(range(5))\n",
    "    temp.remove(i)\n",
    "    test=cancer_data[i::5]\n",
    "    training_setup=[cancer_data[temp[0]::5], cancer_data[temp[1]::5], cancer_data[temp[2]::5], cancer_data[temp[3]::5]]\n",
    "    training=pd.concat(training_setup)\n",
    "\n",
    "    model=Sequential()\n",
    "    s='relu'\n",
    "    model.add(Dense(40, activation=s, input_dim=len(col_names)))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(40, activation=s))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #keras.optimizers.RMSprop(lr=.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(training[col_names].values, training['Class'].values, batch_size=batches, epochs=50, verbose=0)\n",
    "    \n",
    "    nn_prediction=model.predict(test[col_names].values)\n",
    "    nn_prediction=np.ndarray.tolist(nn_prediction)\n",
    "    nn_prediction=[float(nn_prediction[i][0]) for i in range(len(nn_prediction))]\n",
    "    \n",
    "    mean_error.append(np.mean(np.abs(nn_prediction-test['Class'])))\n",
    "    \n",
    "    total_error.append(np.abs(nn_prediction-test['Class']))\n",
    "    \n",
    "    mean_values.append(np.mean(np.abs(test['Class'])))\n",
    "\n",
    "print(mean_error)\n",
    "print(np.mean(mean_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average error of 7.1%, so the random forest wins!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
